{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/icarus_custom/source/css/back-to-top.css","path":"css/back-to-top.css","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/css/insight.css","path":"css/insight.css","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/css/progressbar.css","path":"css/progressbar.css","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/css/search.css","path":"css/search.css","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/images/avatar.png","path":"images/avatar.png","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/images/favicon.svg","path":"images/favicon.svg","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/images/thumbnail.svg","path":"images/thumbnail.svg","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/js/animation.js","path":"js/animation.js","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/js/back-to-top.js","path":"js/back-to-top.js","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/js/clipboard.js","path":"js/clipboard.js","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/js/gallery.js","path":"js/gallery.js","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/js/insight.js","path":"js/insight.js","modified":0,"renderable":1},{"_id":"themes/icarus_custom/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"source/image/response_time.png","path":"image/response_time.png","modified":1,"renderable":0}],"Cache":[{"_id":"themes/icarus_custom/LICENSE","hash":"41f72cd544612bc4589c924c776422b800a4eff7","modified":1551261727704},{"_id":"themes/icarus_custom/_config.yml","hash":"a296141d8759a203cf187ad776da418888c1c02b","modified":1551261727704},{"_id":"themes/icarus_custom/package.json","hash":"4167e65682af257bdf8531a05730e6c42339996d","modified":1551261727712},{"_id":"themes/icarus_custom/languages/en.yml","hash":"b69c91878f30937f50438ff64dffd3f6bf91bcf5","modified":1551261727708},{"_id":"themes/icarus_custom/languages/es.yml","hash":"8827823e5b2ce967566854c9bfebc7c69098b4ac","modified":1551261727708},{"_id":"themes/icarus_custom/languages/fr.yml","hash":"0017f93a5d491a9c0e55911cdc35316762c5a94e","modified":1551261727708},{"_id":"themes/icarus_custom/languages/id.yml","hash":"92d2d19a62a17b6e99f82a014309bbf6c13c9ae8","modified":1551261727708},{"_id":"themes/icarus_custom/languages/ja.yml","hash":"6eed7771de2353d71b720c6e605cceb3f230b12e","modified":1551261727708},{"_id":"themes/icarus_custom/languages/ko.yml","hash":"06d2bb8b66f68f780218e0ba7edffe1e57fac268","modified":1551261727708},{"_id":"themes/icarus_custom/languages/pt-BR.yml","hash":"bcf5bc81ca855d26bbc3b3bfabc7d84429e74b85","modified":1551261727708},{"_id":"themes/icarus_custom/languages/ru.yml","hash":"ba8b4f7d77eb1d1e28aa1f9107bd0bbbdc4cba99","modified":1551261727708},{"_id":"themes/icarus_custom/languages/tr.yml","hash":"eff1c0b3d5c4b328f6dd74a195ff378c898f4d29","modified":1551261727708},{"_id":"themes/icarus_custom/languages/zh-CN.yml","hash":"804f6a1edee49bb6a5ecb8e9d14d3e93eaca37c0","modified":1551261727708},{"_id":"themes/icarus_custom/languages/zh-TW.yml","hash":"79fab0bff625634fb6bb6cadf9c547bd36226dcf","modified":1551261727708},{"_id":"themes/icarus_custom/layout/archive.ejs","hash":"64a81f4c6ca9517169413408d076371e8e09c63a","modified":1551261727708},{"_id":"themes/icarus_custom/layout/categories.ejs","hash":"29d304f2b95a04fbc5e7529f9bdce9648e3545ef","modified":1551261727708},{"_id":"themes/icarus_custom/layout/category.ejs","hash":"bda344da0e6c03899f53abc20ae2a2efab5ab243","modified":1551261727708},{"_id":"themes/icarus_custom/layout/index.ejs","hash":"71120f41d019bf2866a5556747e5e671c8147f85","modified":1551261727708},{"_id":"themes/icarus_custom/layout/layout.ejs","hash":"da63c914247eba116ea5263bfc27a69e96f859b6","modified":1551261727708},{"_id":"themes/icarus_custom/layout/page.ejs","hash":"50170783bac99946ae8af483920568de9b2d9801","modified":1551261727708},{"_id":"themes/icarus_custom/layout/post.ejs","hash":"50170783bac99946ae8af483920568de9b2d9801","modified":1551261727712},{"_id":"themes/icarus_custom/layout/tag.ejs","hash":"1feac7aa842882757a479b8ad427f6a72fce70c4","modified":1551261727712},{"_id":"themes/icarus_custom/layout/tags.ejs","hash":"0c527c6b72386f11c18e8aa5249be8c601e69906","modified":1551261727712},{"_id":"themes/icarus_custom/scripts/index.js","hash":"9203e2ba1f821d945edf20fc277f3c58d22bfd00","modified":1551261727712},{"_id":"source/_posts/NodeJs/NodeJS-Express-의-잔여-메모리와-응답시간.md","hash":"30b0d7f7ac4d0b41246983fe7e69747382eb291a","modified":1551277814202},{"_id":"themes/icarus_custom/includes/common/ConfigGenerator.js","hash":"451397efc7808787419fa3eb6b043c0bd8bbdf30","modified":1551261727704},{"_id":"themes/icarus_custom/includes/common/ConfigValidator.js","hash":"cd3cd12bc042b401825fd7bfd9a6434c8b14e092","modified":1551261727704},{"_id":"themes/icarus_custom/includes/common/utils.js","hash":"c0aeaeb57a42bcc71a92da2249762f91abd83ffe","modified":1551261727704},{"_id":"themes/icarus_custom/includes/filters/highlight.js","hash":"19a4dcd2dee7388544b57e473cfb0fc9eea9623e","modified":1551261727704},{"_id":"themes/icarus_custom/includes/generators/categories.js","hash":"7cb370ac53a05d6b1b9203579716c0ca83d35c36","modified":1551261727704},{"_id":"themes/icarus_custom/includes/generators/category.js","hash":"313e170e55d74526c4e1be7181ef7a21439147c9","modified":1551261727704},{"_id":"themes/icarus_custom/includes/generators/insight.js","hash":"c4b981443927b87cc14a3a583029e13f819d6d71","modified":1551261727704},{"_id":"themes/icarus_custom/includes/generators/tags.js","hash":"8195322c208706427a1cf56361669dca4d86f6f1","modified":1551261727704},{"_id":"themes/icarus_custom/includes/helpers/cdn.js","hash":"7d34ea6400cb3611c374c135304abcb65ef291b7","modified":1551261727704},{"_id":"themes/icarus_custom/includes/helpers/config.js","hash":"173e02987e7a7d5df1e686f6ee4edd8cf494bdd3","modified":1551261727704},{"_id":"themes/icarus_custom/includes/helpers/layout.js","hash":"afdf5e9704cfc087526b4a0403fe7eb04f22190e","modified":1551261727704},{"_id":"themes/icarus_custom/includes/helpers/override.js","hash":"726cf99612fd060753d9da08db2776aec1802e20","modified":1551261727704},{"_id":"themes/icarus_custom/includes/helpers/page.js","hash":"25aeed6449ca381661cec528fe96bbb993026ca9","modified":1551261727704},{"_id":"themes/icarus_custom/includes/helpers/site.js","hash":"f154ddb0dac79fd28ced2b518f8052b42555d0c9","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/article.spec.js","hash":"a805c1a6f03ccb07d73512aef40d38541ddbb0eb","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/comment.spec.js","hash":"02af67eb87482028b223299b20a129756b1c122b","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/config.spec.js","hash":"7a9bac384a73cf9f39173fdb2dfc2813784d8891","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/donate.spec.js","hash":"639b405c9e5dac04c2dc168c2754e50a5c13d197","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/footer.spec.js","hash":"49fabe9c03f3124f0253fa1ee3e69328373ad117","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/icon_link.spec.js","hash":"f2a83ac5ccb74fc6f3dfbd25430e142297d8491c","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/meta.spec.js","hash":"70abe77d3664176ec977316522014ce7e0aa439d","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/navbar.spec.js","hash":"67ebd05fb378439a094a7906f4ea04fbedd8c1b5","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/plugins.spec.js","hash":"3db2046311dd0392aed0ba2d81b51a081131f1de","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/providers.spec.js","hash":"e29473155a35f391fbc53349bdc256cb7600855e","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/search.spec.js","hash":"d981ad203a2002c35d710d33e304f9e99f31cab0","modified":1551261727708},{"_id":"themes/icarus_custom/includes/specs/share.spec.js","hash":"6c04cccec13a656189ab2d917d69d059027d0343","modified":1551261727708},{"_id":"themes/icarus_custom/includes/specs/sidebar.spec.js","hash":"bd500be763486918894e731ce14bc9c4047fb76d","modified":1551261727704},{"_id":"themes/icarus_custom/includes/specs/widgets.spec.js","hash":"eeeaae3ed079033788b19e172cd1f83c5ca8bc4f","modified":1551261727708},{"_id":"themes/icarus_custom/includes/tasks/check_config.js","hash":"ce7626d643737c90dee6b75435ccdec26b89dacf","modified":1551261727708},{"_id":"themes/icarus_custom/includes/tasks/check_deps.js","hash":"cfc357f27116d1b9285a3b0bec35c3e89ae73711","modified":1551261727708},{"_id":"themes/icarus_custom/includes/tasks/welcome.js","hash":"00d1ef8c9609552b82e9a5140b838a9057c59508","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/changyan.ejs","hash":"9ccc7ec354b968e60bdcfcd1dba451d38de61f12","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/disqus.ejs","hash":"b5fff46e453d58baa20028a47fd85923494bb85c","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/facebook.ejs","hash":"b38ea86a1cae48f671501af74d7f109f63fb3d72","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/gitalk.ejs","hash":"ef01396e64ab4f6e62155f0b357bcd903138d611","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/gitment.ejs","hash":"430416210933b7edcbfcc67ede4aa55539da2750","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/isso.ejs","hash":"cc6a43bd24be764086f88ad7c5c97ff04df87e0b","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/livere.ejs","hash":"12ff9a345f6bba2f732f592e39508c2afde89b00","modified":1551261727708},{"_id":"themes/icarus_custom/layout/comment/valine.ejs","hash":"290c5e96a2db27629f5d7d69f7d362e4daba095b","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/article.ejs","hash":"76e4b72b62cf3e34227980aa8c7161ee27b57a7a","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/footer.ejs","hash":"9e57d97a52ad358b5f38cf87a3fda356d2094b6d","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/head.ejs","hash":"bd72ffd5942bb2fd18319d551bbaa59647e33f3c","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/navbar.ejs","hash":"5082ea45df0f79f955143177287d92bcf3832fcf","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/paginator.ejs","hash":"7837d80b27f166161b3deeffb571680025c7d723","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/scripts.ejs","hash":"5414d6bfbf88efa7e72ccf7e44a79d0378ddeb77","modified":1551261727708},{"_id":"themes/icarus_custom/layout/common/widget.ejs","hash":"5417af9f208d2fb5aaeb96031caa261e9683557c","modified":1551261727708},{"_id":"themes/icarus_custom/layout/donate/alipay.ejs","hash":"3290058879973e403a05472a0fe2ac0219d5b961","modified":1551261727708},{"_id":"themes/icarus_custom/layout/donate/patreon.ejs","hash":"8e52a9c28ffaf4b0b786a20977b848c5f60f2274","modified":1551261727708},{"_id":"themes/icarus_custom/layout/donate/paypal.ejs","hash":"3975dee39f9378975b9c10f37d118ad7cb6f5bf6","modified":1551261727708},{"_id":"themes/icarus_custom/layout/donate/wechat.ejs","hash":"051b873e1fc28c1d7c2d6443991b6a2f43813e6b","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/animejs.ejs","hash":"198062ef863c96aa4d6a8225d575afcb60dfb1d1","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/back-to-top.ejs","hash":"79d1118a3d3ebc521ffce452b986b504f0e7d6b7","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/baidu-analytics.ejs","hash":"eb66e313ad43ec4424b2d75bae94e5c8a7568428","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/busuanzi.ejs","hash":"205dedf8f97e328bb3182dc8daebd2e2b2204aca","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/clipboard.ejs","hash":"8662ed9c211f3993b93eedcf5e41c2a1ddbede57","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/gallery.ejs","hash":"ad68fafd923747d6b7c1b5873d00989d1639678c","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/google-analytics.ejs","hash":"282cecb28ac458b71b56cf429c72ffac0f820199","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/hotjar.ejs","hash":"2b97737d802984750a7b4461fcf68818a57a2439","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/mathjax.ejs","hash":"667aabb6b9cb4d707b37975af794d4a3c66b5264","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/outdated-browser.ejs","hash":"fe051093893c64c8575bcc67dc1c146d409e8e80","modified":1551261727708},{"_id":"themes/icarus_custom/layout/plugin/progressbar.ejs","hash":"e594ed6705bccbef27f49d84b6153f6443efbecd","modified":1551261727712},{"_id":"themes/icarus_custom/layout/search/baidu.ejs","hash":"850aa91778100d693a52b10eaa8586c8e3215ee6","modified":1551261727712},{"_id":"themes/icarus_custom/layout/search/google-cse.ejs","hash":"4b881a99325a6a0cebf97ac53e09d8fc67f87d29","modified":1551261727712},{"_id":"themes/icarus_custom/layout/search/insight.ejs","hash":"9a27db2a007582ceee7ca4b1eebddbd456893568","modified":1551261727712},{"_id":"themes/icarus_custom/layout/share/addthis.ejs","hash":"f1c5f337333009d5f00dfbac4864a16ef8f9cb8d","modified":1551261727712},{"_id":"themes/icarus_custom/layout/share/addtoany.ejs","hash":"04cb247d8c83ca7c5b52f3b11bb3ac155b1bc3ab","modified":1551261727712},{"_id":"themes/icarus_custom/layout/share/bdshare.ejs","hash":"f14c8084b7ee16a091f0bd2ae9039e3bfff7e7b7","modified":1551261727712},{"_id":"themes/icarus_custom/layout/share/sharejs.ejs","hash":"65d08316cc479910ea4f526cd1c299d0104daf7f","modified":1551261727712},{"_id":"themes/icarus_custom/layout/share/sharethis.ejs","hash":"4f2c40f790f3be0a4e79db04f02ea41ba2f4d4c0","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/archive.ejs","hash":"eb738a2ac2935ce7a542964d90088613b281dd15","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/category.ejs","hash":"c2a9f2211a21a168c54b0563cdfd58bd25fa39fe","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/links.ejs","hash":"2b707fd65c94b00d8b4c6755fbc6c19709f3d49a","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/profile.ejs","hash":"04ef01227b140b74c0396196dd7a1996f3cccf95","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/recent_posts.ejs","hash":"2166f3190e47bf4746775b5d16654564a88c2041","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/tag.ejs","hash":"8c5b8020ca776cc3ebbc7b723915f3173efc28d4","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/tagcloud.ejs","hash":"d32e7c56e8e2074da16d9141f9a597841d28d07d","modified":1551261727712},{"_id":"themes/icarus_custom/layout/widget/toc.ejs","hash":"bdc6f22602cdabe7c740f1818e0681ff8508fb64","modified":1551261727712},{"_id":"themes/icarus_custom/source/css/back-to-top.css","hash":"5805bee2445e997d64dfe526b08b5fe0bce357eb","modified":1551261727712},{"_id":"themes/icarus_custom/source/css/insight.css","hash":"22943a610d5cfffedfb823c692f4db2b1f37a4c9","modified":1551261727712},{"_id":"themes/icarus_custom/source/css/progressbar.css","hash":"bbc737b7a8feb19901e792c447a846273779d5c3","modified":1551261727712},{"_id":"themes/icarus_custom/source/css/search.css","hash":"c1cb306e075386517ac15bf4ef37c647d37ec6b5","modified":1551261727712},{"_id":"themes/icarus_custom/source/css/style.styl","hash":"efd8abc2609f08800d5642ba5f0ffc430722e0a5","modified":1551261727712},{"_id":"themes/icarus_custom/source/images/avatar.png","hash":"0d8236dcca871735500e9d06bbdbe0853ed6775b","modified":1551261727712},{"_id":"themes/icarus_custom/source/images/favicon.svg","hash":"16fd847265845063a16596761cddb32926073dd2","modified":1551261727712},{"_id":"themes/icarus_custom/source/images/logo.svg","hash":"e9b5c1438ddb576693a15d0713b2a1d9ceda4be9","modified":1551261727712},{"_id":"themes/icarus_custom/source/images/thumbnail.svg","hash":"b9c58ff09ed415e6cf08b42b35faa2bc000d5059","modified":1551261727712},{"_id":"themes/icarus_custom/source/js/animation.js","hash":"d744581909d2d092a584be07c39f9d3f0d009ec7","modified":1551261727712},{"_id":"themes/icarus_custom/source/js/back-to-top.js","hash":"b1dcf30577cefe833dc6151757c0a05ea5b5a643","modified":1551261727712},{"_id":"themes/icarus_custom/source/js/clipboard.js","hash":"6fdd602268727744b6b2c8ad79d684aab3cffda5","modified":1551261727712},{"_id":"themes/icarus_custom/source/js/gallery.js","hash":"88b23abfc3b519413be54533ed0f39e0c68fcdd1","modified":1551261727712},{"_id":"themes/icarus_custom/source/js/insight.js","hash":"8ba56fd5e4232a05ccef5f8b733c7ecca0814633","modified":1551261727712},{"_id":"themes/icarus_custom/source/js/main.js","hash":"3357a1798a994afad0a849a679ca2ed6e0ce2424","modified":1551261727712},{"_id":"source/_posts/NodeJs/Parse/Cluster-환경에서의-Parse-Dashboard.md","hash":"b5767abbde5fb4c2f7ba77d14fb2a57451722be7","modified":1551261727704},{"_id":"public/rss2.xml","hash":"83260315e1851614db788d2223d574ed1435851e","modified":1551277825817},{"_id":"public/post-sitemap.xml","hash":"4874891197f6c228b6e156ccb6d37625db8f200b","modified":1551277825818},{"_id":"public/tag-sitemap.xml","hash":"54e5ff38e8869b1f5c7607388d078a00928bdbb2","modified":1551277826378},{"_id":"public/category-sitemap.xml","hash":"97bc3446811dd66ff70486438425bebc6376061d","modified":1551277826377},{"_id":"public/sitemap.xsl","hash":"4321fa69dc1b8811d32b7a1478e5603e038cea1a","modified":1551268779646},{"_id":"public/sitemap.xml","hash":"826631b0d1360ef6a6eb56794b695f9b606335af","modified":1551277826383},{"_id":"public/content.json","hash":"7ff1f235debb2d0196a07bde5d4712b6d3ddea30","modified":1551272775114},{"_id":"public/2019/02/09/NodeJs/Parse/Cluster-환경에서의-Parse-Dashboard/index.html","hash":"6981316cee5791be242fffc7ae0aa471dedac6c3","modified":1551268779665},{"_id":"public/archives/index.html","hash":"0ad990b3e206148129085524e5ee2fa78f14054a","modified":1551268779665},{"_id":"public/archives/2019/index.html","hash":"433389af14db033485ddaec3e97d66b10b67b4ee","modified":1551268779775},{"_id":"public/archives/2019/02/index.html","hash":"49e54968a6e3e12fa7d3f18949dbd2f3e2313316","modified":1551268779775},{"_id":"public/categories/NodeJs/index.html","hash":"6af32a1d01239324ff09e592e08b4c073f4f92b4","modified":1551277826386},{"_id":"public/categories/NodeJs/Parse/index.html","hash":"45fde3ff065864650849a63b89c712601b8c160d","modified":1551268779776},{"_id":"public/tags/node-js/index.html","hash":"c4f41785d91bf60f9590575edc1865728b0fa4ab","modified":1551277826387},{"_id":"public/tags/parse-dashboard/index.html","hash":"98d0b3969c6c1d71f0a6a350cfae0b015d919789","modified":1551268779776},{"_id":"public/tags/cluster/index.html","hash":"a045a9e069de36b37c4de2705b6abc1ed501786e","modified":1551268779776},{"_id":"public/index.html","hash":"0a3bdb59ba16419b5c5491a9def203c410a25303","modified":1551277826387},{"_id":"public/categories/index.html","hash":"b5a4e74e924b533c2da01697bf7fdba33241033f","modified":1551268779776},{"_id":"public/tags/index.html","hash":"863be28a5c6841e51006d94c8749f82963d9283d","modified":1551268779776},{"_id":"public/2019/02/27/NodeJs/NodeJS-Express-의-잔여-메모리와-응답시간/index.html","hash":"d85d0d3ae5916d17a59b74b5a233132b87a86e24","modified":1551277826386},{"_id":"public/tags/express/index.html","hash":"433a983e8e060cb739bdad8f5319be652c476fbe","modified":1551277826387},{"_id":"public/tags/memory/index.html","hash":"9520b04373f9381741d85cf19843da8b5ba2b7b0","modified":1551277826387},{"_id":"public/tags/response-time/index.html","hash":"a69de8ba16364f032eb7c5381dde63b9c99131c8","modified":1551277826387},{"_id":"public/images/avatar.png","hash":"0d8236dcca871735500e9d06bbdbe0853ed6775b","modified":1551268779780},{"_id":"public/images/favicon.svg","hash":"16fd847265845063a16596761cddb32926073dd2","modified":1551268779780},{"_id":"public/images/logo.svg","hash":"e9b5c1438ddb576693a15d0713b2a1d9ceda4be9","modified":1551268779780},{"_id":"public/images/thumbnail.svg","hash":"b9c58ff09ed415e6cf08b42b35faa2bc000d5059","modified":1551268779780},{"_id":"public/css/back-to-top.css","hash":"5805bee2445e997d64dfe526b08b5fe0bce357eb","modified":1551268779973},{"_id":"public/css/progressbar.css","hash":"bbc737b7a8feb19901e792c447a846273779d5c3","modified":1551268779973},{"_id":"public/css/insight.css","hash":"22943a610d5cfffedfb823c692f4db2b1f37a4c9","modified":1551268779973},{"_id":"public/css/search.css","hash":"c1cb306e075386517ac15bf4ef37c647d37ec6b5","modified":1551268779973},{"_id":"public/js/animation.js","hash":"d744581909d2d092a584be07c39f9d3f0d009ec7","modified":1551268779973},{"_id":"public/js/back-to-top.js","hash":"b1dcf30577cefe833dc6151757c0a05ea5b5a643","modified":1551268779973},{"_id":"public/js/clipboard.js","hash":"6fdd602268727744b6b2c8ad79d684aab3cffda5","modified":1551268779974},{"_id":"public/js/gallery.js","hash":"88b23abfc3b519413be54533ed0f39e0c68fcdd1","modified":1551268779974},{"_id":"public/js/main.js","hash":"3357a1798a994afad0a849a679ca2ed6e0ce2424","modified":1551268779974},{"_id":"public/css/style.css","hash":"fda6a7b3f5bda93129e57d85def5f3e17fd40f41","modified":1551268779975},{"_id":"public/js/insight.js","hash":"8ba56fd5e4232a05ccef5f8b733c7ecca0814633","modified":1551268779975},{"_id":"source/image/response_time.png","hash":"e3758d7f3d7f4025e4fef6fec1318acf29519eed","modified":1551277533893},{"_id":"public/image/response_time.png","hash":"e3758d7f3d7f4025e4fef6fec1318acf29519eed","modified":1551277826390}],"Category":[{"name":"NodeJs","_id":"cjsn5dm6o000f5092vqqmvlew"},{"name":"Parse","parent":"cjsn5dm6o000f5092vqqmvlew","_id":"cjsn5dm6r000h50924jqq7ng6"}],"Data":[],"Page":[],"Post":[{"title":"NodeJS + Express 의 잔여 메모리와 응답시간","date":"2019-02-27T10:08:26.000Z","_content":"\n![응답시간 이미지](/image/response_time.png)\n\n작년 초 지인의 소개로 모 인디게임의 서버 프로그램을 개발하였습니다.\n\n서버의 주 역할은 주기적으로 (짧게는 몇 초부터 길게는 5분) 사용자의 게임 데이터를 서버로 전송해 운영팀이 게임 상황을 파악할 수 있게 해주거나 사용자 차단, 일일 보상 체크 등의 간단한 역할만 수행하고 있습니다.\n\n처음에는 사용자의 수가 적었기 때문에 10 rps (초당 요청 수) 정 도로 아무런 문제가 없었지만 최근 몇 달간 사용자가 급증하기 시작하면서 평균적으로 40rps 를 유지하고 있으며 피크타임 또는 공격을 받을 때는 80 rps까지 올라가는 상황이 벌어지고 있습니다.\n\n이와 동시에 응답시간이 초기에는 1~2s 미만으로 쾌적한 모습을 보여주었지만 요즘 들어 자주 9~15s까지 올라가는 모습을 보고 원인을 파악하고 해결해야 할 필요성이 느껴져서 일주일간의 데이터를 분석하기로 했습니다.\n\n처음에는 피크시간대의 요청 증가로 인해 발생하는 현상이라고 생각했지만, 결과는 전혀 달랐습니다.\n\n피크 시간대에는 1개의 서버 인스턴스가 하나 더 추가되는 것을 고려 하더라도 평소와 성능 차이는 크지 않았으며 오히려 피크 이외의 시간대에 성능 저하가 발생하는 경우가 더 많았습니다.\n\n이상하게 생각되어 해당 시간대의 데이터를 집중적으로 분석하던 중 사용자 증가로 메모리 사용량 초과가 지속해서 발생하였고 PM2의 cluster 수를 2에서 1로 조정하게 되었는데 그 순간 서버의 성능이 개선되었고 성능 저하의 원인을 메모리 사용량을 중점으로 찾아보았습니다.\n\n관찰 결과 PM2 클러스터의 수를 1로 지정했을 때 최초 실행 시 서버의 메모리 사용량은 약 250MB이며 특정 시점부터 메모리 사용량이 증가하면서 384MB까지 증가하였고 이 구간에서 메모리 사용량이 증가할수록 응답시간도 증가하는 것을 확인할 수 있었습니다.\n\n따라서 성능 저하의 문제는 메모리와 관계가 있다는 결론을 내릴 수 있었고 다음과 같은 가능성을 고려하여 자료를 찾아보았습니다.\n\n1. 어디선가 메모리 누수가 진행 중이다.\n2. 서버의 메모리가 부족하다 (최대 512MB)\n3. 비효율적인 로직이 존재한다.\n\n이 중 2번은 현재 1개의 서버 인스턴스 당 1개의 cluster만 돌아가고 있으며 메모리 사용량 모니터링 결과 384MB에 도달하면 cluster instance를 재시작하게 설정한 상황에서도 처리량에는 큰 문제가 없었기 때문에(재시작될 때 해당 인스턴스가 처리 중인 요청은 누락되긴 합니다.) 제외하였으며\n\n3번은 로직이 복잡하지 않고 최근 다음과 같은 작업이 게임 쪽에서 진행 중이라 제외하였습니다.\n\n1. 사용하지 않는 API 제거\n2. out of dated 된 모듈, DB 등의 마이그레이션\n3. 새 스펙에 맞게 서버 및 클라이언트 재개발\n\n결국 중점적으로 찾아보게 된 건 1번 메모리 누수 문제였고 다음과 같은 내용을 알게 되었습니다.\n\n1. Node.js 는 64bit에서는 기본으로 1.4GB를 메모리 한계로 잡는다. 그래서 메모리가 1.4GB 이하인 환경에서는 메모리 제한이 필요하다.\n\n2. V8의 GC 역시 메인 스레드에서 진행되며 사양보다 과도한 요청을 처리하느라 GC가 끼어들 틈이 없다.\n\n3. 잘못된 요청으로 인한 오류가 제대로 처리되지 못하고 구천을 떠돌고 있다.\n\n이 중 2번의 경우에는 순간적으로 80rps로 급상승할 때도 모니터링 결과 GC는 꾸준히 수행 중에 있었으며 메인 스레드의 event loop는 평소 10% 미만의 사용률을 보이고 있었습니다. 따라서 1번과 3번의 해결책을 시도해보았습니다.\n\n1번의 해결책\n\n```bash\nnode --max-old-space-size=512 server.js\n```\n\nPM2의 경우 다음과 같이 설정하면 된다고 합니다.\n\n```json\n{\n  \"apps\": [\n    {\n      \"node_args\": \"--max_old_space_size=512\"\n    }\n  ]\n}\n```\n\n3번의 해결책\n\n```js\napp.use(function(err, req, res, next) {\n  // handle error\n});\n```\n\n하나씩 적용해보면서 결과를 관찰하였는데 3번의 해결책의 경우 의외로 큰 성능 개선을 보여주었습니다. 흔히 툴키드라고 불리는 악성 사용자들의 비정상적인 요청이 처리하지 않은 오류를 발생시켰고 제대로 처리되지 않아 한동안 서버 내부에서 고아 상태가 되었던 것 같습니다. 이러한 부분은 다음 버전부터는 [express-async-errors](https://www.npmjs.com/package/express-async-errors) 모듈 등을 통해 전역적으로 오류를 처리하는 방향으로 결정하였습니다.\n\n1번의 해결책의 경우에는 큰 효과는 못 보고 있는데 PM2에서 재시작하는 부분도 있어서 좀 더 지켜봐야 할 것 같습니다. 다만 메모리 사용량이 이전보다는 완만하게 증가하는 경향을 보이는데 해당 옵션 때문인지는 판단이 잘 안 되고 있습니다.\n\n최종적으로 서버의 응답시간은 다음과 같이 변했습니다.\n\n과거\n\n| Ratio | Response Time |\n| :---: | ------------: |\n|  MAX  |           30s |\n|  99%  |           13s |\n|  95%  |            7s |\n|  50%  |          0.7s |\n\n현재\n\n| Ratio | Response Time |\n| :---: | ------------: |\n|  MAX  |           17s |\n|  99%  |            5s |\n|  95%  |            2s |\n|  50%  |          0.2s |\n\nRPS는 약 10 정도 더 늘어났으며 피크시간대에도 더 나은 성능을 보여주기 시작했습니다.\n\n다만 이 수치는 해당 기간 사용자 수가 20% 이상 증가하여 서버 인스턴스를 평균적으로 1개 정도 추가하였음을 고려하고 보시면 감사하겠습니다.\n\n다음에 좀 더 성능 개선을 하면 어느 정도까지 성능개선이 될지 궁금하네요.\n\n---\n\n참고\n\n[Node.JS ( & pm2 ) Process Memory Limit](https://gist.github.com/scr1p7ed/ee0d96c3795e59244063)\n\n[Production best practices: performance and reliability](http://expressjs.com/en/advanced/best-practice-performance.html)\n\n[Node.js 최적화, 메모리관리를 위한 flag](https://blog.canapio.com/47)\n\n[nodejs 메모리 누수](https://sjh836.tistory.com/106)\n\n[Static Memory Javascript with Object Pools](https://www.html5rocks.com/ko/tutorials/speed/static-mem-pools/)\n\n[Memory Leaks in NodeJS | Quick Overview](https://medium.com/tech-tajawal/memory-leaks-in-nodejs-quick-overview-988c23b24dba)\n","source":"_posts/NodeJs/NodeJS-Express-의-잔여-메모리와-응답시간.md","raw":"---\ntitle: NodeJS + Express 의 잔여 메모리와 응답시간\ndate: 2019-02-27 19:08:26\ntags:\n  - express\n  - memory\n  - node.js\n  - response time\n---\n\n![응답시간 이미지](/image/response_time.png)\n\n작년 초 지인의 소개로 모 인디게임의 서버 프로그램을 개발하였습니다.\n\n서버의 주 역할은 주기적으로 (짧게는 몇 초부터 길게는 5분) 사용자의 게임 데이터를 서버로 전송해 운영팀이 게임 상황을 파악할 수 있게 해주거나 사용자 차단, 일일 보상 체크 등의 간단한 역할만 수행하고 있습니다.\n\n처음에는 사용자의 수가 적었기 때문에 10 rps (초당 요청 수) 정 도로 아무런 문제가 없었지만 최근 몇 달간 사용자가 급증하기 시작하면서 평균적으로 40rps 를 유지하고 있으며 피크타임 또는 공격을 받을 때는 80 rps까지 올라가는 상황이 벌어지고 있습니다.\n\n이와 동시에 응답시간이 초기에는 1~2s 미만으로 쾌적한 모습을 보여주었지만 요즘 들어 자주 9~15s까지 올라가는 모습을 보고 원인을 파악하고 해결해야 할 필요성이 느껴져서 일주일간의 데이터를 분석하기로 했습니다.\n\n처음에는 피크시간대의 요청 증가로 인해 발생하는 현상이라고 생각했지만, 결과는 전혀 달랐습니다.\n\n피크 시간대에는 1개의 서버 인스턴스가 하나 더 추가되는 것을 고려 하더라도 평소와 성능 차이는 크지 않았으며 오히려 피크 이외의 시간대에 성능 저하가 발생하는 경우가 더 많았습니다.\n\n이상하게 생각되어 해당 시간대의 데이터를 집중적으로 분석하던 중 사용자 증가로 메모리 사용량 초과가 지속해서 발생하였고 PM2의 cluster 수를 2에서 1로 조정하게 되었는데 그 순간 서버의 성능이 개선되었고 성능 저하의 원인을 메모리 사용량을 중점으로 찾아보았습니다.\n\n관찰 결과 PM2 클러스터의 수를 1로 지정했을 때 최초 실행 시 서버의 메모리 사용량은 약 250MB이며 특정 시점부터 메모리 사용량이 증가하면서 384MB까지 증가하였고 이 구간에서 메모리 사용량이 증가할수록 응답시간도 증가하는 것을 확인할 수 있었습니다.\n\n따라서 성능 저하의 문제는 메모리와 관계가 있다는 결론을 내릴 수 있었고 다음과 같은 가능성을 고려하여 자료를 찾아보았습니다.\n\n1. 어디선가 메모리 누수가 진행 중이다.\n2. 서버의 메모리가 부족하다 (최대 512MB)\n3. 비효율적인 로직이 존재한다.\n\n이 중 2번은 현재 1개의 서버 인스턴스 당 1개의 cluster만 돌아가고 있으며 메모리 사용량 모니터링 결과 384MB에 도달하면 cluster instance를 재시작하게 설정한 상황에서도 처리량에는 큰 문제가 없었기 때문에(재시작될 때 해당 인스턴스가 처리 중인 요청은 누락되긴 합니다.) 제외하였으며\n\n3번은 로직이 복잡하지 않고 최근 다음과 같은 작업이 게임 쪽에서 진행 중이라 제외하였습니다.\n\n1. 사용하지 않는 API 제거\n2. out of dated 된 모듈, DB 등의 마이그레이션\n3. 새 스펙에 맞게 서버 및 클라이언트 재개발\n\n결국 중점적으로 찾아보게 된 건 1번 메모리 누수 문제였고 다음과 같은 내용을 알게 되었습니다.\n\n1. Node.js 는 64bit에서는 기본으로 1.4GB를 메모리 한계로 잡는다. 그래서 메모리가 1.4GB 이하인 환경에서는 메모리 제한이 필요하다.\n\n2. V8의 GC 역시 메인 스레드에서 진행되며 사양보다 과도한 요청을 처리하느라 GC가 끼어들 틈이 없다.\n\n3. 잘못된 요청으로 인한 오류가 제대로 처리되지 못하고 구천을 떠돌고 있다.\n\n이 중 2번의 경우에는 순간적으로 80rps로 급상승할 때도 모니터링 결과 GC는 꾸준히 수행 중에 있었으며 메인 스레드의 event loop는 평소 10% 미만의 사용률을 보이고 있었습니다. 따라서 1번과 3번의 해결책을 시도해보았습니다.\n\n1번의 해결책\n\n```bash\nnode --max-old-space-size=512 server.js\n```\n\nPM2의 경우 다음과 같이 설정하면 된다고 합니다.\n\n```json\n{\n  \"apps\": [\n    {\n      \"node_args\": \"--max_old_space_size=512\"\n    }\n  ]\n}\n```\n\n3번의 해결책\n\n```js\napp.use(function(err, req, res, next) {\n  // handle error\n});\n```\n\n하나씩 적용해보면서 결과를 관찰하였는데 3번의 해결책의 경우 의외로 큰 성능 개선을 보여주었습니다. 흔히 툴키드라고 불리는 악성 사용자들의 비정상적인 요청이 처리하지 않은 오류를 발생시켰고 제대로 처리되지 않아 한동안 서버 내부에서 고아 상태가 되었던 것 같습니다. 이러한 부분은 다음 버전부터는 [express-async-errors](https://www.npmjs.com/package/express-async-errors) 모듈 등을 통해 전역적으로 오류를 처리하는 방향으로 결정하였습니다.\n\n1번의 해결책의 경우에는 큰 효과는 못 보고 있는데 PM2에서 재시작하는 부분도 있어서 좀 더 지켜봐야 할 것 같습니다. 다만 메모리 사용량이 이전보다는 완만하게 증가하는 경향을 보이는데 해당 옵션 때문인지는 판단이 잘 안 되고 있습니다.\n\n최종적으로 서버의 응답시간은 다음과 같이 변했습니다.\n\n과거\n\n| Ratio | Response Time |\n| :---: | ------------: |\n|  MAX  |           30s |\n|  99%  |           13s |\n|  95%  |            7s |\n|  50%  |          0.7s |\n\n현재\n\n| Ratio | Response Time |\n| :---: | ------------: |\n|  MAX  |           17s |\n|  99%  |            5s |\n|  95%  |            2s |\n|  50%  |          0.2s |\n\nRPS는 약 10 정도 더 늘어났으며 피크시간대에도 더 나은 성능을 보여주기 시작했습니다.\n\n다만 이 수치는 해당 기간 사용자 수가 20% 이상 증가하여 서버 인스턴스를 평균적으로 1개 정도 추가하였음을 고려하고 보시면 감사하겠습니다.\n\n다음에 좀 더 성능 개선을 하면 어느 정도까지 성능개선이 될지 궁금하네요.\n\n---\n\n참고\n\n[Node.JS ( & pm2 ) Process Memory Limit](https://gist.github.com/scr1p7ed/ee0d96c3795e59244063)\n\n[Production best practices: performance and reliability](http://expressjs.com/en/advanced/best-practice-performance.html)\n\n[Node.js 최적화, 메모리관리를 위한 flag](https://blog.canapio.com/47)\n\n[nodejs 메모리 누수](https://sjh836.tistory.com/106)\n\n[Static Memory Javascript with Object Pools](https://www.html5rocks.com/ko/tutorials/speed/static-mem-pools/)\n\n[Memory Leaks in NodeJS | Quick Overview](https://medium.com/tech-tajawal/memory-leaks-in-nodejs-quick-overview-988c23b24dba)\n","slug":"NodeJs/NodeJS-Express-의-잔여-메모리와-응답시간","published":1,"updated":"2019-02-27T14:30:14.202Z","_id":"cjsn5dm6500005092vjegkopc","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/image/response_time.png\" alt=\"응답시간 이미지\"></p>\n<p>작년 초 지인의 소개로 모 인디게임의 서버 프로그램을 개발하였습니다.</p>\n<p>서버의 주 역할은 주기적으로 (짧게는 몇 초부터 길게는 5분) 사용자의 게임 데이터를 서버로 전송해 운영팀이 게임 상황을 파악할 수 있게 해주거나 사용자 차단, 일일 보상 체크 등의 간단한 역할만 수행하고 있습니다.</p>\n<p>처음에는 사용자의 수가 적었기 때문에 10 rps (초당 요청 수) 정 도로 아무런 문제가 없었지만 최근 몇 달간 사용자가 급증하기 시작하면서 평균적으로 40rps 를 유지하고 있으며 피크타임 또는 공격을 받을 때는 80 rps까지 올라가는 상황이 벌어지고 있습니다.</p>\n<p>이와 동시에 응답시간이 초기에는 1~2s 미만으로 쾌적한 모습을 보여주었지만 요즘 들어 자주 9~15s까지 올라가는 모습을 보고 원인을 파악하고 해결해야 할 필요성이 느껴져서 일주일간의 데이터를 분석하기로 했습니다.</p>\n<p>처음에는 피크시간대의 요청 증가로 인해 발생하는 현상이라고 생각했지만, 결과는 전혀 달랐습니다.</p>\n<p>피크 시간대에는 1개의 서버 인스턴스가 하나 더 추가되는 것을 고려 하더라도 평소와 성능 차이는 크지 않았으며 오히려 피크 이외의 시간대에 성능 저하가 발생하는 경우가 더 많았습니다.</p>\n<p>이상하게 생각되어 해당 시간대의 데이터를 집중적으로 분석하던 중 사용자 증가로 메모리 사용량 초과가 지속해서 발생하였고 PM2의 cluster 수를 2에서 1로 조정하게 되었는데 그 순간 서버의 성능이 개선되었고 성능 저하의 원인을 메모리 사용량을 중점으로 찾아보았습니다.</p>\n<p>관찰 결과 PM2 클러스터의 수를 1로 지정했을 때 최초 실행 시 서버의 메모리 사용량은 약 250MB이며 특정 시점부터 메모리 사용량이 증가하면서 384MB까지 증가하였고 이 구간에서 메모리 사용량이 증가할수록 응답시간도 증가하는 것을 확인할 수 있었습니다.</p>\n<p>따라서 성능 저하의 문제는 메모리와 관계가 있다는 결론을 내릴 수 있었고 다음과 같은 가능성을 고려하여 자료를 찾아보았습니다.</p>\n<ol>\n<li>어디선가 메모리 누수가 진행 중이다.</li>\n<li>서버의 메모리가 부족하다 (최대 512MB)</li>\n<li>비효율적인 로직이 존재한다.</li>\n</ol>\n<p>이 중 2번은 현재 1개의 서버 인스턴스 당 1개의 cluster만 돌아가고 있으며 메모리 사용량 모니터링 결과 384MB에 도달하면 cluster instance를 재시작하게 설정한 상황에서도 처리량에는 큰 문제가 없었기 때문에(재시작될 때 해당 인스턴스가 처리 중인 요청은 누락되긴 합니다.) 제외하였으며</p>\n<p>3번은 로직이 복잡하지 않고 최근 다음과 같은 작업이 게임 쪽에서 진행 중이라 제외하였습니다.</p>\n<ol>\n<li>사용하지 않는 API 제거</li>\n<li>out of dated 된 모듈, DB 등의 마이그레이션</li>\n<li>새 스펙에 맞게 서버 및 클라이언트 재개발</li>\n</ol>\n<p>결국 중점적으로 찾아보게 된 건 1번 메모리 누수 문제였고 다음과 같은 내용을 알게 되었습니다.</p>\n<ol>\n<li><p>Node.js 는 64bit에서는 기본으로 1.4GB를 메모리 한계로 잡는다. 그래서 메모리가 1.4GB 이하인 환경에서는 메모리 제한이 필요하다.</p>\n</li>\n<li><p>V8의 GC 역시 메인 스레드에서 진행되며 사양보다 과도한 요청을 처리하느라 GC가 끼어들 틈이 없다.</p>\n</li>\n<li><p>잘못된 요청으로 인한 오류가 제대로 처리되지 못하고 구천을 떠돌고 있다.</p>\n</li>\n</ol>\n<p>이 중 2번의 경우에는 순간적으로 80rps로 급상승할 때도 모니터링 결과 GC는 꾸준히 수행 중에 있었으며 메인 스레드의 event loop는 평소 10% 미만의 사용률을 보이고 있었습니다. 따라서 1번과 3번의 해결책을 시도해보았습니다.</p>\n<p>1번의 해결책</p>\n<figure class=\"highlight bash hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node --max-old-space-size=512 server.js</span><br></pre></td></tr></table></figure>\n<p>PM2의 경우 다음과 같이 설정하면 된다고 합니다.</p>\n<figure class=\"highlight json hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"hljs-attr\">\"apps\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"hljs-attr\">\"node_args\"</span>: <span class=\"hljs-string\">\"--max_old_space_size=512\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>3번의 해결책</p>\n<figure class=\"highlight js hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">app.use(<span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span>(<span class=\"hljs-params\">err, req, res, next</span>) </span>&#123;</span><br><span class=\"line\">  <span class=\"hljs-comment\">// handle error</span></span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>하나씩 적용해보면서 결과를 관찰하였는데 3번의 해결책의 경우 의외로 큰 성능 개선을 보여주었습니다. 흔히 툴키드라고 불리는 악성 사용자들의 비정상적인 요청이 처리하지 않은 오류를 발생시켰고 제대로 처리되지 않아 한동안 서버 내부에서 고아 상태가 되었던 것 같습니다. 이러한 부분은 다음 버전부터는 <a href=\"https://www.npmjs.com/package/express-async-errors\" target=\"_blank\" rel=\"noopener\">express-async-errors</a> 모듈 등을 통해 전역적으로 오류를 처리하는 방향으로 결정하였습니다.</p>\n<p>1번의 해결책의 경우에는 큰 효과는 못 보고 있는데 PM2에서 재시작하는 부분도 있어서 좀 더 지켜봐야 할 것 같습니다. 다만 메모리 사용량이 이전보다는 완만하게 증가하는 경향을 보이는데 해당 옵션 때문인지는 판단이 잘 안 되고 있습니다.</p>\n<p>최종적으로 서버의 응답시간은 다음과 같이 변했습니다.</p>\n<p>과거</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Ratio</th>\n<th style=\"text-align:right\">Response Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">MAX</td>\n<td style=\"text-align:right\">30s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">99%</td>\n<td style=\"text-align:right\">13s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">95%</td>\n<td style=\"text-align:right\">7s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">50%</td>\n<td style=\"text-align:right\">0.7s</td>\n</tr>\n</tbody>\n</table>\n<p>현재</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Ratio</th>\n<th style=\"text-align:right\">Response Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">MAX</td>\n<td style=\"text-align:right\">17s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">99%</td>\n<td style=\"text-align:right\">5s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">95%</td>\n<td style=\"text-align:right\">2s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">50%</td>\n<td style=\"text-align:right\">0.2s</td>\n</tr>\n</tbody>\n</table>\n<p>RPS는 약 10 정도 더 늘어났으며 피크시간대에도 더 나은 성능을 보여주기 시작했습니다.</p>\n<p>다만 이 수치는 해당 기간 사용자 수가 20% 이상 증가하여 서버 인스턴스를 평균적으로 1개 정도 추가하였음을 고려하고 보시면 감사하겠습니다.</p>\n<p>다음에 좀 더 성능 개선을 하면 어느 정도까지 성능개선이 될지 궁금하네요.</p>\n<hr>\n<p>참고</p>\n<p><a href=\"https://gist.github.com/scr1p7ed/ee0d96c3795e59244063\" target=\"_blank\" rel=\"noopener\">Node.JS ( &amp; pm2 ) Process Memory Limit</a></p>\n<p><a href=\"http://expressjs.com/en/advanced/best-practice-performance.html\" target=\"_blank\" rel=\"noopener\">Production best practices: performance and reliability</a></p>\n<p><a href=\"https://blog.canapio.com/47\" target=\"_blank\" rel=\"noopener\">Node.js 최적화, 메모리관리를 위한 flag</a></p>\n<p><a href=\"https://sjh836.tistory.com/106\" target=\"_blank\" rel=\"noopener\">nodejs 메모리 누수</a></p>\n<p><a href=\"https://www.html5rocks.com/ko/tutorials/speed/static-mem-pools/\" target=\"_blank\" rel=\"noopener\">Static Memory Javascript with Object Pools</a></p>\n<p><a href=\"https://medium.com/tech-tajawal/memory-leaks-in-nodejs-quick-overview-988c23b24dba\" target=\"_blank\" rel=\"noopener\">Memory Leaks in NodeJS | Quick Overview</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"/image/response_time.png\" alt=\"응답시간 이미지\"></p>\n<p>작년 초 지인의 소개로 모 인디게임의 서버 프로그램을 개발하였습니다.</p>\n<p>서버의 주 역할은 주기적으로 (짧게는 몇 초부터 길게는 5분) 사용자의 게임 데이터를 서버로 전송해 운영팀이 게임 상황을 파악할 수 있게 해주거나 사용자 차단, 일일 보상 체크 등의 간단한 역할만 수행하고 있습니다.</p>\n<p>처음에는 사용자의 수가 적었기 때문에 10 rps (초당 요청 수) 정 도로 아무런 문제가 없었지만 최근 몇 달간 사용자가 급증하기 시작하면서 평균적으로 40rps 를 유지하고 있으며 피크타임 또는 공격을 받을 때는 80 rps까지 올라가는 상황이 벌어지고 있습니다.</p>\n<p>이와 동시에 응답시간이 초기에는 1~2s 미만으로 쾌적한 모습을 보여주었지만 요즘 들어 자주 9~15s까지 올라가는 모습을 보고 원인을 파악하고 해결해야 할 필요성이 느껴져서 일주일간의 데이터를 분석하기로 했습니다.</p>\n<p>처음에는 피크시간대의 요청 증가로 인해 발생하는 현상이라고 생각했지만, 결과는 전혀 달랐습니다.</p>\n<p>피크 시간대에는 1개의 서버 인스턴스가 하나 더 추가되는 것을 고려 하더라도 평소와 성능 차이는 크지 않았으며 오히려 피크 이외의 시간대에 성능 저하가 발생하는 경우가 더 많았습니다.</p>\n<p>이상하게 생각되어 해당 시간대의 데이터를 집중적으로 분석하던 중 사용자 증가로 메모리 사용량 초과가 지속해서 발생하였고 PM2의 cluster 수를 2에서 1로 조정하게 되었는데 그 순간 서버의 성능이 개선되었고 성능 저하의 원인을 메모리 사용량을 중점으로 찾아보았습니다.</p>\n<p>관찰 결과 PM2 클러스터의 수를 1로 지정했을 때 최초 실행 시 서버의 메모리 사용량은 약 250MB이며 특정 시점부터 메모리 사용량이 증가하면서 384MB까지 증가하였고 이 구간에서 메모리 사용량이 증가할수록 응답시간도 증가하는 것을 확인할 수 있었습니다.</p>\n<p>따라서 성능 저하의 문제는 메모리와 관계가 있다는 결론을 내릴 수 있었고 다음과 같은 가능성을 고려하여 자료를 찾아보았습니다.</p>\n<ol>\n<li>어디선가 메모리 누수가 진행 중이다.</li>\n<li>서버의 메모리가 부족하다 (최대 512MB)</li>\n<li>비효율적인 로직이 존재한다.</li>\n</ol>\n<p>이 중 2번은 현재 1개의 서버 인스턴스 당 1개의 cluster만 돌아가고 있으며 메모리 사용량 모니터링 결과 384MB에 도달하면 cluster instance를 재시작하게 설정한 상황에서도 처리량에는 큰 문제가 없었기 때문에(재시작될 때 해당 인스턴스가 처리 중인 요청은 누락되긴 합니다.) 제외하였으며</p>\n<p>3번은 로직이 복잡하지 않고 최근 다음과 같은 작업이 게임 쪽에서 진행 중이라 제외하였습니다.</p>\n<ol>\n<li>사용하지 않는 API 제거</li>\n<li>out of dated 된 모듈, DB 등의 마이그레이션</li>\n<li>새 스펙에 맞게 서버 및 클라이언트 재개발</li>\n</ol>\n<p>결국 중점적으로 찾아보게 된 건 1번 메모리 누수 문제였고 다음과 같은 내용을 알게 되었습니다.</p>\n<ol>\n<li><p>Node.js 는 64bit에서는 기본으로 1.4GB를 메모리 한계로 잡는다. 그래서 메모리가 1.4GB 이하인 환경에서는 메모리 제한이 필요하다.</p>\n</li>\n<li><p>V8의 GC 역시 메인 스레드에서 진행되며 사양보다 과도한 요청을 처리하느라 GC가 끼어들 틈이 없다.</p>\n</li>\n<li><p>잘못된 요청으로 인한 오류가 제대로 처리되지 못하고 구천을 떠돌고 있다.</p>\n</li>\n</ol>\n<p>이 중 2번의 경우에는 순간적으로 80rps로 급상승할 때도 모니터링 결과 GC는 꾸준히 수행 중에 있었으며 메인 스레드의 event loop는 평소 10% 미만의 사용률을 보이고 있었습니다. 따라서 1번과 3번의 해결책을 시도해보았습니다.</p>\n<p>1번의 해결책</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node --max-old-space-size=512 server.js</span><br></pre></td></tr></table></figure>\n<p>PM2의 경우 다음과 같이 설정하면 된다고 합니다.</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"apps\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"node_args\"</span>: <span class=\"string\">\"--max_old_space_size=512\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>3번의 해결책</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">app.use(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">err, req, res, next</span>) </span>&#123;</span><br><span class=\"line\">  <span class=\"comment\">// handle error</span></span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p>하나씩 적용해보면서 결과를 관찰하였는데 3번의 해결책의 경우 의외로 큰 성능 개선을 보여주었습니다. 흔히 툴키드라고 불리는 악성 사용자들의 비정상적인 요청이 처리하지 않은 오류를 발생시켰고 제대로 처리되지 않아 한동안 서버 내부에서 고아 상태가 되었던 것 같습니다. 이러한 부분은 다음 버전부터는 <a href=\"https://www.npmjs.com/package/express-async-errors\" target=\"_blank\" rel=\"noopener\">express-async-errors</a> 모듈 등을 통해 전역적으로 오류를 처리하는 방향으로 결정하였습니다.</p>\n<p>1번의 해결책의 경우에는 큰 효과는 못 보고 있는데 PM2에서 재시작하는 부분도 있어서 좀 더 지켜봐야 할 것 같습니다. 다만 메모리 사용량이 이전보다는 완만하게 증가하는 경향을 보이는데 해당 옵션 때문인지는 판단이 잘 안 되고 있습니다.</p>\n<p>최종적으로 서버의 응답시간은 다음과 같이 변했습니다.</p>\n<p>과거</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Ratio</th>\n<th style=\"text-align:right\">Response Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">MAX</td>\n<td style=\"text-align:right\">30s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">99%</td>\n<td style=\"text-align:right\">13s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">95%</td>\n<td style=\"text-align:right\">7s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">50%</td>\n<td style=\"text-align:right\">0.7s</td>\n</tr>\n</tbody>\n</table>\n<p>현재</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Ratio</th>\n<th style=\"text-align:right\">Response Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">MAX</td>\n<td style=\"text-align:right\">17s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">99%</td>\n<td style=\"text-align:right\">5s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">95%</td>\n<td style=\"text-align:right\">2s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">50%</td>\n<td style=\"text-align:right\">0.2s</td>\n</tr>\n</tbody>\n</table>\n<p>RPS는 약 10 정도 더 늘어났으며 피크시간대에도 더 나은 성능을 보여주기 시작했습니다.</p>\n<p>다만 이 수치는 해당 기간 사용자 수가 20% 이상 증가하여 서버 인스턴스를 평균적으로 1개 정도 추가하였음을 고려하고 보시면 감사하겠습니다.</p>\n<p>다음에 좀 더 성능 개선을 하면 어느 정도까지 성능개선이 될지 궁금하네요.</p>\n<hr>\n<p>참고</p>\n<p><a href=\"https://gist.github.com/scr1p7ed/ee0d96c3795e59244063\" target=\"_blank\" rel=\"noopener\">Node.JS ( &amp; pm2 ) Process Memory Limit</a></p>\n<p><a href=\"http://expressjs.com/en/advanced/best-practice-performance.html\" target=\"_blank\" rel=\"noopener\">Production best practices: performance and reliability</a></p>\n<p><a href=\"https://blog.canapio.com/47\" target=\"_blank\" rel=\"noopener\">Node.js 최적화, 메모리관리를 위한 flag</a></p>\n<p><a href=\"https://sjh836.tistory.com/106\" target=\"_blank\" rel=\"noopener\">nodejs 메모리 누수</a></p>\n<p><a href=\"https://www.html5rocks.com/ko/tutorials/speed/static-mem-pools/\" target=\"_blank\" rel=\"noopener\">Static Memory Javascript with Object Pools</a></p>\n<p><a href=\"https://medium.com/tech-tajawal/memory-leaks-in-nodejs-quick-overview-988c23b24dba\" target=\"_blank\" rel=\"noopener\">Memory Leaks in NodeJS | Quick Overview</a></p>\n"},{"title":"Cluster 환경에서의 Parse Dashboard","date":"2019-02-08T17:58:46.000Z","_content":"\nNode.js와 웹 프레임워크를 사용해 구현한 웹 서버는 생산성이나 편의성 면에서 확실히 매력이 있습니다.\n\nNPM의 방대한 라이브러리와 Javascript의 다양한 자료들은 부족한 실력에도 원하는 목적을 달성하게 도와줍니다.\n\n저는 그중에서도 Node.js + Express + Parse Server + MongoDB + Parse Dashboard 구조를 주로 사용하는데\n\n개인적으로는 Java를 좋아하지만, 학교 수업에서 배운 Tomcat + Servlet은 개인적으로는 취향에 맞지 않았고\n\nSQL은 다들 사용하니 제 주변에선 잘 안 쓰는 MongoDB를 써보고 싶은 마음도 있긴 했지만\n\n과거 Facebook에서 Parse.com이라는 서비스를 운영했을 때 사용한 경험이 좋아서 선호하는 경향도 있습니다.\n\nParse가 오픈소스가 아닌 Facebook에서 호스팅 서비스를 할 당시에는 서버 인프라를 제가 고려할 필요가 없었지만\n\n서비스 종료 후 오픈소스로 공개된 이후에는 사용자에게는 두 가지 선택지가 생겼습니다.\n\nCloud 업체가 Parse를 호스팅하여 제공하는 서비스를 사용.\n\n직접 Parse 서버를 호스팅하여 사용.\n\n처음 이 소식을 접했을 때는 국내 업체는 Parse 호스팅을 제공하는 업체를 찾지 못하였고 외국 업체 일부가 있었으며\n\n업체별로 어느 정도 커스텀이 들어갔기 때문에 제가 기억하는 Parse의 모습은 찾을 수 없었습니다.\n\n또한, 당시에는 지금보다 더 지식이 없었기 때문에 외국 포럼을 검색하다 발견해서 커스텀하여 사용하고 있던\n\nCloud Job을 해당 호스팅 업체에 맞춰 마이그레이션 할 자신이 없었기 때문에 이왕 배우는 거 처음부터 손대보자는 생각으로\n\n직접 Parse 호스팅에 도전하였습니다.\n\n열심히 공부하면서 로컬에서 단순히 Node 서버만 띄웠을 때 (PM2나 cluster 사용 X)는 Dashboard에 접속하는 데 문제가 없었지만.\n\nCloud 서버에 올리고 더 나은 성능과 가용성을 위해 Cluster를 적용하게 되었고\n\n기쁜 마음으로 Dashboard에 접속한 저에게는 하얀 화면의 검은 글씨가 기다릴 뿐이었습니다.\n\n이 문제를 해결하기 위해 stack overflow도 검색하고 다양한 문서를 찾아봤지만, 해당 문제는 공식 문서에도 없었으며 (지금은 모르겠습니다)\n\n다른 개발자들이 올린 질문의 답변도 어느 하나 저에게 도움이 되는 답변이 없었으며 엉뚱한 답변이 많았습니다.\n\n\n\n그러던 중 해당 문제의 솔루션에 대해 언급한 내용을 github의 issues 중 하나의 댓글에서 발견하였고\n\n(왜 이게 공식 문서에 포함이 되지 않는지 아직도 의문스러운데 어느 정도 규모있는 기업에서는 Parse Dashboard를 사용하지 않고 다른 솔루션을 사용하지 않을까 싶습니다)\n\n\n\n해당 내용은 다음과 같습니다.\n\n\n\n\n\nI ran into this issue after upgrading to 1.1.2 and I hunted down the root cause.\n\nAs per PR #774 (this line of code), the cookie secret will be set to a random value if you do not set it yourself. This is intentional and documented in the CLI.\n\nSo, if you are running in a load balanced environment (or in using NodeJS cluster) be sure to set your cookieSessionSecret:\n\nFrom CLI:\n```\n--cookieSessionSecret \"your-secret-here\"\n```\n\nFrom NodeJS (options is the 2nd argument of constructor):\n\n```\nnew ParseDashboard({\n// settings here\n}, {\n  cookieSessionSecret: 'your-secret-here'\n});\n```\n\n즉, 별도의 cookieSession값을 지정하지 않으면 랜덤으로 값이 지정되는데 cluster 환경 또는 로드밸런싱 환경에서는 프로세스마다 해당 값이 다르게 지정되기 때문에 발생하는 문제 같습니다.\n\n\n\n이 문제에 대해 해결책을 알려준 JeremyPlease 에게 감사합니다.","source":"_posts/NodeJs/Parse/Cluster-환경에서의-Parse-Dashboard.md","raw":"---\ntitle: Cluster 환경에서의 Parse Dashboard\ndate: 2019-02-09 02:58:46\ntags:\n    - parse-dashboard\n    - cluster\n    - node.js\n---\n\nNode.js와 웹 프레임워크를 사용해 구현한 웹 서버는 생산성이나 편의성 면에서 확실히 매력이 있습니다.\n\nNPM의 방대한 라이브러리와 Javascript의 다양한 자료들은 부족한 실력에도 원하는 목적을 달성하게 도와줍니다.\n\n저는 그중에서도 Node.js + Express + Parse Server + MongoDB + Parse Dashboard 구조를 주로 사용하는데\n\n개인적으로는 Java를 좋아하지만, 학교 수업에서 배운 Tomcat + Servlet은 개인적으로는 취향에 맞지 않았고\n\nSQL은 다들 사용하니 제 주변에선 잘 안 쓰는 MongoDB를 써보고 싶은 마음도 있긴 했지만\n\n과거 Facebook에서 Parse.com이라는 서비스를 운영했을 때 사용한 경험이 좋아서 선호하는 경향도 있습니다.\n\nParse가 오픈소스가 아닌 Facebook에서 호스팅 서비스를 할 당시에는 서버 인프라를 제가 고려할 필요가 없었지만\n\n서비스 종료 후 오픈소스로 공개된 이후에는 사용자에게는 두 가지 선택지가 생겼습니다.\n\nCloud 업체가 Parse를 호스팅하여 제공하는 서비스를 사용.\n\n직접 Parse 서버를 호스팅하여 사용.\n\n처음 이 소식을 접했을 때는 국내 업체는 Parse 호스팅을 제공하는 업체를 찾지 못하였고 외국 업체 일부가 있었으며\n\n업체별로 어느 정도 커스텀이 들어갔기 때문에 제가 기억하는 Parse의 모습은 찾을 수 없었습니다.\n\n또한, 당시에는 지금보다 더 지식이 없었기 때문에 외국 포럼을 검색하다 발견해서 커스텀하여 사용하고 있던\n\nCloud Job을 해당 호스팅 업체에 맞춰 마이그레이션 할 자신이 없었기 때문에 이왕 배우는 거 처음부터 손대보자는 생각으로\n\n직접 Parse 호스팅에 도전하였습니다.\n\n열심히 공부하면서 로컬에서 단순히 Node 서버만 띄웠을 때 (PM2나 cluster 사용 X)는 Dashboard에 접속하는 데 문제가 없었지만.\n\nCloud 서버에 올리고 더 나은 성능과 가용성을 위해 Cluster를 적용하게 되었고\n\n기쁜 마음으로 Dashboard에 접속한 저에게는 하얀 화면의 검은 글씨가 기다릴 뿐이었습니다.\n\n이 문제를 해결하기 위해 stack overflow도 검색하고 다양한 문서를 찾아봤지만, 해당 문제는 공식 문서에도 없었으며 (지금은 모르겠습니다)\n\n다른 개발자들이 올린 질문의 답변도 어느 하나 저에게 도움이 되는 답변이 없었으며 엉뚱한 답변이 많았습니다.\n\n\n\n그러던 중 해당 문제의 솔루션에 대해 언급한 내용을 github의 issues 중 하나의 댓글에서 발견하였고\n\n(왜 이게 공식 문서에 포함이 되지 않는지 아직도 의문스러운데 어느 정도 규모있는 기업에서는 Parse Dashboard를 사용하지 않고 다른 솔루션을 사용하지 않을까 싶습니다)\n\n\n\n해당 내용은 다음과 같습니다.\n\n\n\n\n\nI ran into this issue after upgrading to 1.1.2 and I hunted down the root cause.\n\nAs per PR #774 (this line of code), the cookie secret will be set to a random value if you do not set it yourself. This is intentional and documented in the CLI.\n\nSo, if you are running in a load balanced environment (or in using NodeJS cluster) be sure to set your cookieSessionSecret:\n\nFrom CLI:\n```\n--cookieSessionSecret \"your-secret-here\"\n```\n\nFrom NodeJS (options is the 2nd argument of constructor):\n\n```\nnew ParseDashboard({\n// settings here\n}, {\n  cookieSessionSecret: 'your-secret-here'\n});\n```\n\n즉, 별도의 cookieSession값을 지정하지 않으면 랜덤으로 값이 지정되는데 cluster 환경 또는 로드밸런싱 환경에서는 프로세스마다 해당 값이 다르게 지정되기 때문에 발생하는 문제 같습니다.\n\n\n\n이 문제에 대해 해결책을 알려준 JeremyPlease 에게 감사합니다.","slug":"NodeJs/Parse/Cluster-환경에서의-Parse-Dashboard","published":1,"updated":"2019-02-27T10:02:07.704Z","_id":"cjsn5dm6h00095092gnftolmm","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Node.js와 웹 프레임워크를 사용해 구현한 웹 서버는 생산성이나 편의성 면에서 확실히 매력이 있습니다.</p>\n<p>NPM의 방대한 라이브러리와 Javascript의 다양한 자료들은 부족한 실력에도 원하는 목적을 달성하게 도와줍니다.</p>\n<p>저는 그중에서도 Node.js + Express + Parse Server + MongoDB + Parse Dashboard 구조를 주로 사용하는데</p>\n<p>개인적으로는 Java를 좋아하지만, 학교 수업에서 배운 Tomcat + Servlet은 개인적으로는 취향에 맞지 않았고</p>\n<p>SQL은 다들 사용하니 제 주변에선 잘 안 쓰는 MongoDB를 써보고 싶은 마음도 있긴 했지만</p>\n<p>과거 Facebook에서 Parse.com이라는 서비스를 운영했을 때 사용한 경험이 좋아서 선호하는 경향도 있습니다.</p>\n<p>Parse가 오픈소스가 아닌 Facebook에서 호스팅 서비스를 할 당시에는 서버 인프라를 제가 고려할 필요가 없었지만</p>\n<p>서비스 종료 후 오픈소스로 공개된 이후에는 사용자에게는 두 가지 선택지가 생겼습니다.</p>\n<p>Cloud 업체가 Parse를 호스팅하여 제공하는 서비스를 사용.</p>\n<p>직접 Parse 서버를 호스팅하여 사용.</p>\n<p>처음 이 소식을 접했을 때는 국내 업체는 Parse 호스팅을 제공하는 업체를 찾지 못하였고 외국 업체 일부가 있었으며</p>\n<p>업체별로 어느 정도 커스텀이 들어갔기 때문에 제가 기억하는 Parse의 모습은 찾을 수 없었습니다.</p>\n<p>또한, 당시에는 지금보다 더 지식이 없었기 때문에 외국 포럼을 검색하다 발견해서 커스텀하여 사용하고 있던</p>\n<p>Cloud Job을 해당 호스팅 업체에 맞춰 마이그레이션 할 자신이 없었기 때문에 이왕 배우는 거 처음부터 손대보자는 생각으로</p>\n<p>직접 Parse 호스팅에 도전하였습니다.</p>\n<p>열심히 공부하면서 로컬에서 단순히 Node 서버만 띄웠을 때 (PM2나 cluster 사용 X)는 Dashboard에 접속하는 데 문제가 없었지만.</p>\n<p>Cloud 서버에 올리고 더 나은 성능과 가용성을 위해 Cluster를 적용하게 되었고</p>\n<p>기쁜 마음으로 Dashboard에 접속한 저에게는 하얀 화면의 검은 글씨가 기다릴 뿐이었습니다.</p>\n<p>이 문제를 해결하기 위해 stack overflow도 검색하고 다양한 문서를 찾아봤지만, 해당 문제는 공식 문서에도 없었으며 (지금은 모르겠습니다)</p>\n<p>다른 개발자들이 올린 질문의 답변도 어느 하나 저에게 도움이 되는 답변이 없었으며 엉뚱한 답변이 많았습니다.</p>\n<p>그러던 중 해당 문제의 솔루션에 대해 언급한 내용을 github의 issues 중 하나의 댓글에서 발견하였고</p>\n<p>(왜 이게 공식 문서에 포함이 되지 않는지 아직도 의문스러운데 어느 정도 규모있는 기업에서는 Parse Dashboard를 사용하지 않고 다른 솔루션을 사용하지 않을까 싶습니다)</p>\n<p>해당 내용은 다음과 같습니다.</p>\n<p>I ran into this issue after upgrading to 1.1.2 and I hunted down the root cause.</p>\n<p>As per PR #774 (this line of code), the cookie secret will be set to a random value if you do not set it yourself. This is intentional and documented in the CLI.</p>\n<p>So, if you are running in a load balanced environment (or in using NodeJS cluster) be sure to set your cookieSessionSecret:</p>\n<p>From CLI:<br><figure class=\"highlight ada hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-comment\">--cookieSessionSecret \"your-secret-here\"</span></span><br></pre></td></tr></table></figure></p>\n<p>From NodeJS (options is the 2nd argument of constructor):</p>\n<figure class=\"highlight haxe hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">ParseDashboard</span>(&#123;</span><br><span class=\"line\"><span class=\"hljs-comment\">// settings here</span></span><br><span class=\"line\">&#125;, &#123;</span><br><span class=\"line\">  cookieSessionSecret: <span class=\"hljs-type\"></span>'your-secret-<span class=\"hljs-keyword\">here</span><span class=\"hljs-string\">'</span></span><br><span class=\"line\"><span class=\"hljs-string\">&#125;);</span></span><br></pre></td></tr></table></figure>\n<p>즉, 별도의 cookieSession값을 지정하지 않으면 랜덤으로 값이 지정되는데 cluster 환경 또는 로드밸런싱 환경에서는 프로세스마다 해당 값이 다르게 지정되기 때문에 발생하는 문제 같습니다.</p>\n<p>이 문제에 대해 해결책을 알려준 JeremyPlease 에게 감사합니다.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Node.js와 웹 프레임워크를 사용해 구현한 웹 서버는 생산성이나 편의성 면에서 확실히 매력이 있습니다.</p>\n<p>NPM의 방대한 라이브러리와 Javascript의 다양한 자료들은 부족한 실력에도 원하는 목적을 달성하게 도와줍니다.</p>\n<p>저는 그중에서도 Node.js + Express + Parse Server + MongoDB + Parse Dashboard 구조를 주로 사용하는데</p>\n<p>개인적으로는 Java를 좋아하지만, 학교 수업에서 배운 Tomcat + Servlet은 개인적으로는 취향에 맞지 않았고</p>\n<p>SQL은 다들 사용하니 제 주변에선 잘 안 쓰는 MongoDB를 써보고 싶은 마음도 있긴 했지만</p>\n<p>과거 Facebook에서 Parse.com이라는 서비스를 운영했을 때 사용한 경험이 좋아서 선호하는 경향도 있습니다.</p>\n<p>Parse가 오픈소스가 아닌 Facebook에서 호스팅 서비스를 할 당시에는 서버 인프라를 제가 고려할 필요가 없었지만</p>\n<p>서비스 종료 후 오픈소스로 공개된 이후에는 사용자에게는 두 가지 선택지가 생겼습니다.</p>\n<p>Cloud 업체가 Parse를 호스팅하여 제공하는 서비스를 사용.</p>\n<p>직접 Parse 서버를 호스팅하여 사용.</p>\n<p>처음 이 소식을 접했을 때는 국내 업체는 Parse 호스팅을 제공하는 업체를 찾지 못하였고 외국 업체 일부가 있었으며</p>\n<p>업체별로 어느 정도 커스텀이 들어갔기 때문에 제가 기억하는 Parse의 모습은 찾을 수 없었습니다.</p>\n<p>또한, 당시에는 지금보다 더 지식이 없었기 때문에 외국 포럼을 검색하다 발견해서 커스텀하여 사용하고 있던</p>\n<p>Cloud Job을 해당 호스팅 업체에 맞춰 마이그레이션 할 자신이 없었기 때문에 이왕 배우는 거 처음부터 손대보자는 생각으로</p>\n<p>직접 Parse 호스팅에 도전하였습니다.</p>\n<p>열심히 공부하면서 로컬에서 단순히 Node 서버만 띄웠을 때 (PM2나 cluster 사용 X)는 Dashboard에 접속하는 데 문제가 없었지만.</p>\n<p>Cloud 서버에 올리고 더 나은 성능과 가용성을 위해 Cluster를 적용하게 되었고</p>\n<p>기쁜 마음으로 Dashboard에 접속한 저에게는 하얀 화면의 검은 글씨가 기다릴 뿐이었습니다.</p>\n<p>이 문제를 해결하기 위해 stack overflow도 검색하고 다양한 문서를 찾아봤지만, 해당 문제는 공식 문서에도 없었으며 (지금은 모르겠습니다)</p>\n<p>다른 개발자들이 올린 질문의 답변도 어느 하나 저에게 도움이 되는 답변이 없었으며 엉뚱한 답변이 많았습니다.</p>\n<p>그러던 중 해당 문제의 솔루션에 대해 언급한 내용을 github의 issues 중 하나의 댓글에서 발견하였고</p>\n<p>(왜 이게 공식 문서에 포함이 되지 않는지 아직도 의문스러운데 어느 정도 규모있는 기업에서는 Parse Dashboard를 사용하지 않고 다른 솔루션을 사용하지 않을까 싶습니다)</p>\n<p>해당 내용은 다음과 같습니다.</p>\n<p>I ran into this issue after upgrading to 1.1.2 and I hunted down the root cause.</p>\n<p>As per PR #774 (this line of code), the cookie secret will be set to a random value if you do not set it yourself. This is intentional and documented in the CLI.</p>\n<p>So, if you are running in a load balanced environment (or in using NodeJS cluster) be sure to set your cookieSessionSecret:</p>\n<p>From CLI:<br><figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--cookieSessionSecret \"your-secret-here\"</span></span><br></pre></td></tr></table></figure></p>\n<p>From NodeJS (options is the 2nd argument of constructor):</p>\n<figure class=\"highlight haxe\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">new</span> <span class=\"type\">ParseDashboard</span>(&#123;</span><br><span class=\"line\"><span class=\"comment\">// settings here</span></span><br><span class=\"line\">&#125;, &#123;</span><br><span class=\"line\">  cookieSessionSecret: <span class=\"type\"></span>'your-secret-<span class=\"keyword\">here</span><span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">&#125;);</span></span><br></pre></td></tr></table></figure>\n<p>즉, 별도의 cookieSession값을 지정하지 않으면 랜덤으로 값이 지정되는데 cluster 환경 또는 로드밸런싱 환경에서는 프로세스마다 해당 값이 다르게 지정되기 때문에 발생하는 문제 같습니다.</p>\n<p>이 문제에 대해 해결책을 알려준 JeremyPlease 에게 감사합니다.</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjsn5dm6h00095092gnftolmm","category_id":"cjsn5dm6o000f5092vqqmvlew","_id":"cjsn5dm6r000i5092d27zuwv4"},{"post_id":"cjsn5dm6h00095092gnftolmm","category_id":"cjsn5dm6r000h50924jqq7ng6","_id":"cjsn5dm6r000j5092mw5vqe35"},{"post_id":"cjsn5dm6500005092vjegkopc","category_id":"cjsn5dm6o000f5092vqqmvlew","_id":"cjsnariu50000yt92h0m4eezc"}],"PostTag":[{"post_id":"cjsn5dm6500005092vjegkopc","tag_id":"cjsn5dm6b00015092gba2geuk","_id":"cjsn5dm6f00055092u4fhf692"},{"post_id":"cjsn5dm6500005092vjegkopc","tag_id":"cjsn5dm6d00025092c01m45ql","_id":"cjsn5dm6f00065092706ea65c"},{"post_id":"cjsn5dm6500005092vjegkopc","tag_id":"cjsn5dm6e00035092c5iyjlgl","_id":"cjsn5dm6f00075092uv4gv6vh"},{"post_id":"cjsn5dm6500005092vjegkopc","tag_id":"cjsn5dm6f00045092lxchmee9","_id":"cjsn5dm6f00085092w5xhy1rl"},{"post_id":"cjsn5dm6h00095092gnftolmm","tag_id":"cjsn5dm6i000a5092nhwogoq5","_id":"cjsn5dm6j000c5092sirfvw7u"},{"post_id":"cjsn5dm6h00095092gnftolmm","tag_id":"cjsn5dm6j000b5092d8e8i5lw","_id":"cjsn5dm6j000d50928y7stdvw"},{"post_id":"cjsn5dm6h00095092gnftolmm","tag_id":"cjsn5dm6e00035092c5iyjlgl","_id":"cjsn5dm6j000e50925fp2gnid"}],"Tag":[{"name":"express","_id":"cjsn5dm6b00015092gba2geuk"},{"name":"memory","_id":"cjsn5dm6d00025092c01m45ql"},{"name":"node.js","_id":"cjsn5dm6e00035092c5iyjlgl"},{"name":"response time","_id":"cjsn5dm6f00045092lxchmee9"},{"name":"parse-dashboard","_id":"cjsn5dm6i000a5092nhwogoq5"},{"name":"cluster","_id":"cjsn5dm6j000b5092d8e8i5lw"}]}}